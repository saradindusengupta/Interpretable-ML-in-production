{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UiNxsd4_q9wq"
      },
      "source": [
        "### What-If Tool - model comparison\n",
        "This notebook shows use of the [What-If Tool](https://pair-code.github.io/what-if-tool) to compare perfomance of two models on the same dataset.\n",
        "\n",
        "This notebook trains a linear classifier and a DNN on the [UCI census problem](https://archive.ics.uci.edu/ml/datasets/census+income) (predicting whether a person earns more than $50K from their census information).\n",
        "\n",
        "It then visualizes the results of the trained classifiers on test data using the What-If Tool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qqB2tjOMETmr"
      },
      "outputs": [],
      "source": [
        "#@title Install the What-If Tool widget if running in colab {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  !pip install --upgrade witwidget\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jlwjF-Nnmoww"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-20 08:45:48.310310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-20 08:45:48.505887: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-20 08:45:48.531089: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-05-20 08:45:48.531110: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-05-20 08:45:49.394617: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-05-20 08:45:49.394686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-05-20 08:45:49.394690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "#@title Define helper functions {display-mode: \"form\"}\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import functools\n",
        "\n",
        "# Creates a tf feature spec from the dataframe and columns specified.\n",
        "def create_feature_spec(df, columns=None):\n",
        "    feature_spec = {}\n",
        "    if columns == None:\n",
        "        columns = df.columns.values.tolist()\n",
        "    for f in columns:\n",
        "        if df[f].dtype is np.dtype(np.int64):\n",
        "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
        "        elif df[f].dtype is np.dtype(np.float64):\n",
        "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.float32)\n",
        "        else:\n",
        "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.string)\n",
        "    return feature_spec\n",
        "\n",
        "# Creates simple numeric and categorical feature columns from a feature spec and a\n",
        "# list of columns from that spec to use.\n",
        "#\n",
        "# NOTE: Models might perform better with some feature engineering such as bucketed\n",
        "# numeric columns and hash-bucket/embedding columns for categorical features.\n",
        "def create_feature_columns(columns, feature_spec):\n",
        "    ret = []\n",
        "    for col in columns:\n",
        "        if feature_spec[col].dtype is tf.int64 or feature_spec[col].dtype is tf.float32:\n",
        "            ret.append(tf.feature_column.numeric_column(col))\n",
        "        else:\n",
        "            ret.append(tf.feature_column.indicator_column(\n",
        "                tf.feature_column.categorical_column_with_vocabulary_list(col, list(df[col].unique()))))\n",
        "    return ret\n",
        "\n",
        "# An input function for providing input to a model from tf.Examples\n",
        "def tfexamples_input_fn(examples, feature_spec, label, mode=tf.estimator.ModeKeys.EVAL,\n",
        "                       num_epochs=None, \n",
        "                       batch_size=64):\n",
        "    def ex_generator():\n",
        "        for i in range(len(examples)):\n",
        "            yield examples[i].SerializeToString()\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "      ex_generator, tf.dtypes.string, tf.TensorShape([]))\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))\n",
        "    dataset = dataset.repeat(num_epochs)\n",
        "    return dataset\n",
        "\n",
        "# Parses Tf.Example protos into features for the input function.\n",
        "def parse_tf_example(example_proto, label, feature_spec):\n",
        "    parsed_features = tf.io.parse_example(serialized=example_proto, features=feature_spec)\n",
        "    target = parsed_features.pop(label)\n",
        "    return parsed_features, target\n",
        "\n",
        "# Converts a dataframe into a list of tf.Example protos.\n",
        "def df_to_examples(df, columns=None):\n",
        "    examples = []\n",
        "    if columns == None:\n",
        "        columns = df.columns.values.tolist()\n",
        "    for index, row in df.iterrows():\n",
        "        example = tf.train.Example()\n",
        "        for col in columns:\n",
        "            if df[col].dtype is np.dtype(np.int64):\n",
        "                example.features.feature[col].int64_list.value.append(int(row[col]))\n",
        "            elif df[col].dtype is np.dtype(np.float64):\n",
        "                example.features.feature[col].float_list.value.append(row[col])\n",
        "            elif row[col] == row[col]:\n",
        "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
        "        examples.append(example)\n",
        "    return examples\n",
        "\n",
        "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
        "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
        "def make_label_column_numeric(df, label_column, test):\n",
        "  df[label_column] = np.where(test(df[label_column]), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "nu398ARdeuxe",
        "outputId": "e17d4aff-d0f9-498c-ffa7-83314a57e03f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>Education-Num</th>\n",
              "      <th>Capital-Gain</th>\n",
              "      <th>Capital-Loss</th>\n",
              "      <th>Hours-per-week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>32561.000000</td>\n",
              "      <td>3.256100e+04</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>38.581647</td>\n",
              "      <td>1.897784e+05</td>\n",
              "      <td>10.080679</td>\n",
              "      <td>1077.648844</td>\n",
              "      <td>87.303830</td>\n",
              "      <td>40.437456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.640433</td>\n",
              "      <td>1.055500e+05</td>\n",
              "      <td>2.572720</td>\n",
              "      <td>7385.292085</td>\n",
              "      <td>402.960219</td>\n",
              "      <td>12.347429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.228500e+04</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>1.178270e+05</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>1.783560e+05</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>2.370510e+05</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>1.484705e+06</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>4356.000000</td>\n",
              "      <td>99.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Age        fnlwgt  Education-Num  Capital-Gain  Capital-Loss  \\\n",
              "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
              "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
              "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
              "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
              "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
              "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
              "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
              "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
              "\n",
              "       Hours-per-week  \n",
              "count    32561.000000  \n",
              "mean        40.437456  \n",
              "std         12.347429  \n",
              "min          1.000000  \n",
              "25%         40.000000  \n",
              "50%         40.000000  \n",
              "75%         45.000000  \n",
              "max         99.000000  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Read training dataset from CSV {display-mode: \"form\"}\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Set the path to the CSV containing the dataset to train on.\n",
        "csv_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "\n",
        "# Set the column names for the columns in the CSV. If the CSV's first line is a header line containing\n",
        "# the column names, then set this to None.\n",
        "csv_columns = [\n",
        "  \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital-Status\",\n",
        "  \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital-Gain\", \"Capital-Loss\",\n",
        "  \"Hours-per-week\", \"Country\", \"Over-50K\"]\n",
        "\n",
        "# Read the dataset from the provided CSV and print out information about it.\n",
        "df = pd.read_csv(csv_path, names=csv_columns, skipinitialspace=True)\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "67DYIFxoevt2"
      },
      "outputs": [],
      "source": [
        "#@title Specify input columns and column to predict {display-mode: \"form\"}\n",
        "import numpy as np\n",
        "\n",
        "# Set the column in the dataset you wish for the model to predict\n",
        "label_column = 'Over-50K'\n",
        "\n",
        "# Make the label column numeric (0 and 1), for use in our model.\n",
        "# In this case, examples with a target value of '>50K' are considered to be in\n",
        "# the '1' (positive) class and all other examples are considered to be in the\n",
        "# '0' (negative) class.\n",
        "make_label_column_numeric(df, label_column, lambda val: val == '>50K')\n",
        "\n",
        "# Set list of all columns from the dataset we will use for model input.\n",
        "input_features = [\n",
        "  'Age', 'Workclass', 'Education', 'Marital-Status', 'Occupation',\n",
        "  'Relationship', 'Race', 'Sex', 'Capital-Gain', 'Capital-Loss',\n",
        "  'Hours-per-week', 'Country']\n",
        "\n",
        "# Create a list containing all input features and the label column\n",
        "features_and_labels = input_features + [label_column]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BV4f_4_Lex22"
      },
      "outputs": [],
      "source": [
        "#@title Convert dataset to tf.Example protos {display-mode: \"form\"}\n",
        "\n",
        "examples = df_to_examples(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YyLr-_0de1Ii"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpbmk9c_se\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpbmk9c_se', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /home/saradindu/anaconda3/lib/python3.9/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /tmp/ipykernel_2037806/455709305.py:44: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use output_signature instead\n",
            "WARNING:tensorflow:From /tmp/ipykernel_2037806/455709305.py:44: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use output_signature instead\n",
            "WARNING:tensorflow:From /home/saradindu/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-20 08:46:46.607533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2023-05-20 08:46:46.607554: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2023-05-20 08:46:46.607566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (saradindu-ubuntu): /proc/driver/nvidia/version does not exist\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/saradindu/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/ftrl.py:173: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-20 08:46:47.329981: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-20 08:46:47.364894: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpbmk9c_se/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.6931472, step = 0\n",
            "INFO:tensorflow:global_step/sec: 282.467\n",
            "INFO:tensorflow:loss = 13.57868, step = 100 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.218\n",
            "INFO:tensorflow:loss = 16.102236, step = 200 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.55\n",
            "INFO:tensorflow:loss = 0.9100683, step = 300 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.742\n",
            "INFO:tensorflow:loss = 0.6667075, step = 400 (0.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.227\n",
            "INFO:tensorflow:loss = 0.5530878, step = 500 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 272.802\n",
            "INFO:tensorflow:loss = 0.5593339, step = 600 (0.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 291.568\n",
            "INFO:tensorflow:loss = 0.5048593, step = 700 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.564\n",
            "INFO:tensorflow:loss = 1.4142936, step = 800 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.983\n",
            "INFO:tensorflow:loss = 3.5133889, step = 900 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.689\n",
            "INFO:tensorflow:loss = 0.6727071, step = 1000 (0.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.156\n",
            "INFO:tensorflow:loss = 2.9214337, step = 1100 (0.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 294.359\n",
            "INFO:tensorflow:loss = 1.0971092, step = 1200 (0.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 303.836\n",
            "INFO:tensorflow:loss = 1.7314196, step = 1300 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.153\n",
            "INFO:tensorflow:loss = 0.41847274, step = 1400 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.696\n",
            "INFO:tensorflow:loss = 0.91235554, step = 1500 (0.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.933\n",
            "INFO:tensorflow:loss = 1.473811, step = 1600 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.342\n",
            "INFO:tensorflow:loss = 7.9437175, step = 1700 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.038\n",
            "INFO:tensorflow:loss = 0.3817254, step = 1800 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.955\n",
            "INFO:tensorflow:loss = 1.1537654, step = 1900 (0.306 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpbmk9c_se/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
            "INFO:tensorflow:Loss for final step: 0.21710585.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x7fed157836d0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Create and train the linear classifier {display-mode: \"form\"}\n",
        "\n",
        "num_steps = 2000  #@param {type: \"number\"}\n",
        "\n",
        "# Create a feature spec for the classifier\n",
        "feature_spec = create_feature_spec(df, features_and_labels)\n",
        "\n",
        "# Define and train the classifier\n",
        "train_inpf = functools.partial(tfexamples_input_fn, examples, feature_spec, label_column)\n",
        "classifier = tf.estimator.LinearClassifier(\n",
        "    feature_columns=create_feature_columns(input_features, feature_spec))\n",
        "classifier.train(train_inpf, steps=num_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbZuyaJsufkz",
        "outputId": "6dfc87ad-d770-4502-8755-5b108d0e828f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpy_alg1xe\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpy_alg1xe', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-20 08:47:04.049013: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
            "type_id: TFT_OPTIONAL\n",
            "args {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_TENSOR\n",
            "    args {\n",
            "      type_id: TFT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\twhile inferring type of node 'dnn/zero_fraction/cond/output/_18'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpy_alg1xe/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 52.78889, step = 0\n",
            "INFO:tensorflow:global_step/sec: 297.507\n",
            "INFO:tensorflow:loss = 2.231799, step = 100 (0.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 293.571\n",
            "INFO:tensorflow:loss = 1.0818714, step = 200 (0.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.778\n",
            "INFO:tensorflow:loss = 0.53454626, step = 300 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.507\n",
            "INFO:tensorflow:loss = 0.39099637, step = 400 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.224\n",
            "INFO:tensorflow:loss = 0.48821574, step = 500 (0.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.105\n",
            "INFO:tensorflow:loss = 1.040622, step = 600 (0.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.657\n",
            "INFO:tensorflow:loss = 0.46352246, step = 700 (0.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 302.188\n",
            "INFO:tensorflow:loss = 0.43450025, step = 800 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 286.487\n",
            "INFO:tensorflow:loss = 0.41055262, step = 900 (0.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.471\n",
            "INFO:tensorflow:loss = 0.5087823, step = 1000 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.079\n",
            "INFO:tensorflow:loss = 0.69129926, step = 1100 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.02\n",
            "INFO:tensorflow:loss = 0.5791211, step = 1200 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.449\n",
            "INFO:tensorflow:loss = 0.40042365, step = 1300 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.676\n",
            "INFO:tensorflow:loss = 0.5871805, step = 1400 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 282.251\n",
            "INFO:tensorflow:loss = 0.5652126, step = 1500 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.604\n",
            "INFO:tensorflow:loss = 1.2367208, step = 1600 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.576\n",
            "INFO:tensorflow:loss = 0.61142385, step = 1700 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.01\n",
            "INFO:tensorflow:loss = 0.45446593, step = 1800 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.845\n",
            "INFO:tensorflow:loss = 0.47696114, step = 1900 (0.300 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpy_alg1xe/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
            "INFO:tensorflow:Loss for final step: 0.37737674.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7feca135a070>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Create and train the DNN classifier {display-mode: \"form\"}\n",
        "num_steps_2 = 2000  #@param {type: \"number\"}\n",
        "\n",
        "classifier2 = tf.estimator.DNNClassifier(\n",
        "    feature_columns=create_feature_columns(input_features, feature_spec),\n",
        "    hidden_units=[128, 64, 32])\n",
        "classifier2.train(train_inpf, steps=num_steps_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "resources": {
            "http://localhost:8080/data/plugins_listing": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/font-roboto/RxZJdnzeo3R5zSexge8UUZBw1xU1rKptJj_0jans920.woff2": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/font-roboto/d-6IYplOFocCacKzxwXSOJBw1xU1rKptJj_0jans920.woff2": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/font-roboto/oMMgfZMQthOryQo9n22dcuvvDin1pK8aKteLpeZ5c0A.woff2": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/font-roboto/vPcynSL0qHq_6dX7lKVByXYhjbSpvc47ee6xR_80Hnw.woff2": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "NUQVro76e38Q",
        "outputId": "086e0d08-6895-42ce-cec3-c2a015996d23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Invoke What-If Tool for test data and the trained models {display-mode: \"form\"}\n",
        "\n",
        "num_datapoints = 2000  #@param {type: \"number\"}\n",
        "tool_height_in_px = 1000  #@param {type: \"number\"}\n",
        "\n",
        "from witwidget.notebook.visualization import WitConfigBuilder\n",
        "from witwidget.notebook.visualization import WitWidget\n",
        "\n",
        "# Load up the test dataset\n",
        "test_csv_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
        "test_df = pd.read_csv(test_csv_path, names=csv_columns, skipinitialspace=True,\n",
        "  skiprows=1)\n",
        "make_label_column_numeric(test_df, label_column, lambda val: val == '>50K.')\n",
        "test_examples = df_to_examples(test_df[0:num_datapoints])\n",
        "\n",
        "# Setup the tool with the test examples and the trained classifier\n",
        "config_builder = WitConfigBuilder(test_examples[0:num_datapoints]).set_estimator_and_feature_spec(\n",
        "    classifier, feature_spec).set_compare_estimator_and_feature_spec(\n",
        "    classifier2, feature_spec).set_label_vocab(['Under 50K', 'Over 50K'])\n",
        "a = WitWidget(config_builder, height=tool_height_in_px)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "WIT Model Comparison",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
